---
title: "Final Project: Data Ethics and Policy"
authors:
  - name: Christy Hsu
    affiliation: Georgetown University
    roles: writing
    corresponding: true
df-print: kable
bibliography: project.bib
title-block-banner: '#E5DCC8'
format:
  html:
    df-print: kable
    # embed-resources: true
  pdf:
    link-citations: true
prefer-html: true
---

## Abstract

This project looked into an attempt in the fifties that set out to measure individual tolerance and use that measure to evaluate the impact the anti-Communism Cold War agenda—both abroad and at home—had on U.S. citizens. I saw the picking up of this 70-year-old survey data, and the analysis that accompanied it, as a chance to stroll through the data ethics concerns that can arise when holding the hope to learn about the world from data

## Introduction

The online poll data library host by Roper Center was where I first came across the Stouffer Study of 1954 *Communism, Conformity, and Civil Liberties: A Cross-Section of the Nation Speaks Its Mind* by Samuel Andrew Stouffer[@fundfortherepublicCommunismConformityAmp2020]And, I gain access to the entire dataset on ICPSR[@stoufferCommunismConformityCivil1992]


![](image/stouffer-cover.png){width=50%}

I found Stouffer's attempt in the fifties to design public opion polls and, construct an innovative way of measuring the latent properties tolerance and fear in at the individual level very interesting. The tolerance scale and the perception of internal communist danger scale are not included in the data, thus a major part of this project involved returning these two target variables in order to complete the picture and reproduce that basis on which  Stouffer's was primary based. I learned much from this practice of reading and researching that past effort into conceptualizing and ooperationalizing tolerance and fear, and got my hands dirty to really apply those framing and method to the data. It gave me a chance to reflect on the many artistic and arbitrary decisions that the researcher made throughout this data analysis process.

```{r}
library(tidyverse)
library(glmnet)
library(caret)
```
## Harvest from Historical Data collection efforts: a more friendly format

In terms of not violate the redistribution policy of ICPSR, here won't be providing the converted files, rather STATA .do and .dct files constructed by the author (derived from the codebook)

│   ├── read-ascii-files
│   │   ├── gp-decode.do
│   │   ├── lead-decode.do
│   │   ├── sample1.dct
│   │   └── sample2.dct

## Returning target variables to the data

The tolerance that Stouffer argued upon.[@stouffer1955communism]

#### Preparing the `code_df` data frame

1. Cleaning column names and binding the two samples
```{r}
# read the coded csv files for both samples
public_df <- read_csv('data/converted/coded-public.csv')
lead_df <- read_csv('data/converted/coded-leader.csv')
```
```{r}
# for the variables from 150 on distinguish those from public sample and those from leader sample since they represent different survey questions

public_df <- public_df |>
  rename(
    public_v150 = v150,
    public_v151 = v151,
    public_v152 = v152
  )
lead_df <- lead_df |>
  rename(
    lead_v150 = v150,
    lead_v151 = v151
  )

# sample specific questions to the other sample, I filled the empty entries with 54
lead_df <- lead_df |>
  mutate(public_v150 = 54, public_v151 = 54, public_v152 = 54)
public_df <- public_df |>
  mutate(lead_v150 = 54, lead_v151 = 54)
```

1. Adding Binary and Ternary Variables `leader`,`interested` and `categorizer`: these are the variables that Stouffer specified in his book as ways to divide the respondents and make comparisons.
```{r}
code_df <- bind_rows(public_df, lead_df)
code_df <- code_df |> mutate(leader = case_when(
  lead_v150 == 54 ~ 0,
  TRUE ~ 1
))
code_df |> count(leader)
```
```{r}
code_df <- code_df |> mutate(interested = case_when(
    v123 == 1 ~ 'more',
    v123 == 2 ~ 'more',
    TRUE ~ 'less'
)
)
code_df |> count(leader, interested) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()
```

```{r}
code_df <- code_df |> mutate(categorizer = case_when(
  v127 %in% c(1, 2) ~ 'agree',
  v127 == 8 ~'dont know',
  TRUE ~ 'disagree'
))
```
```{r}
code_df |> count(leader, categorizer)|> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()
```

## Scale1: Willingness to Tolerate Nonconformist

#### Conceptual Tolerance and Operational Tolerance

The questionnaires used to rank respondents into six tolerance groups focused on four types of nonconformists:

* A person who is against all churches and religion (atheist)
* A person who favors government ownership (socialist)
* An alleged communist (someone whose loyalty has been questioned by a Congressional Committee but swears under oath they have never been a communist)
* An admitted communist

respondent were asked about their approval of 3 types of disposition against the above nonconfromist, and whether they agree or disagree the limitation or deprivation of the nonconformist's civil liberties, for example:

1. Freedom speech:

   * "If \_\_\_ wants to make a speech in your community, should he be allowed to speak or not?"

2. Book censor:

   * "Suppose he wrote a book that is in your public library. Somebody in your community suggests the book should be removed. Would you favor removing it, or not?"

3. Employment:

   * Should a radio singer who is a nonconformist be fired or not?
   * Should a college or university teacher be fired or not?
   * Should a high school teacher be fired or not?
   * Should someone working in a defense plant be fired or not?
   * Should a store clerk be fired or not?

4. Boycott:

   * "Suppose the radio program he is on advertises a brand of soap. Somebody in your community suggests you stop buying that soap. Would you stop or not?"

#### 0 to 5: Scaling Individual Tolerance

I ran into many challenges replicating Stouffer’s results. Both the overall proportions across tolerance rankings, was unable to reproduce the group counts applying further breakdowns, such as by age, region, education, thus for comparison.

```{r}
code_df <- code_df |> mutate(tolerance_group = NA_character_)
tolernace_items <- c(
  'v100', 'v101', 'v102',
  'v104', 'v32', 'v34',
  'v103', 'v35', 'v37',
  'v108', 'v109', 'v113',
  'v106', 'v107', 'v110'
)
```

```{r}
# df0 <- code_df |> filter(
#   ((v100 == 1) + (v101 == 5) + (v102 == 5) < 2) &
#   ((v104 == 5) + (v32 == 1) + (v34 == 5) < 2) &
#   ((v103 == 5) + (v35 == 1) + (v37 == 5) < 2) &
#   ((v108 == 5) + (v109 == 1) + (v113 == 5) < 2) &
#   ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) < 2)) |> dplyr::select(
#     all_of(tolernace_items))
# df0 |> View()
```
```{r}
## sanity check
df5 <- code_df |> filter(
  ((v100 == 1) + (v101 == 5) + (v102 == 5) >= 2) &
  ((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2) &
  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &
  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &
  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2)) |> dplyr::select(
    all_of(tolernace_items))
# df5
df3 <- code_df |> filter(!((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2)) |> filter(
  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &
  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &
  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2)) |> dplyr::select(
    all_of(tolernace_items))
# df3 |> View()
```
```{r}
code_df <- code_df |> mutate(tolerance_group = NA_character_)

condition_filter <- function(df, condition, group_name){
  df <- df |> mutate(
    tolerance_group = case_when(
      is.na(tolerance_group) & !!rlang::enquo(condition) ~ group_name,
      TRUE ~ tolerance_group
    )
  )
  return(df)
}
```

```{r}
code_df <- code_df |> condition_filter(
  ((v100 == 1) + (v101 == 5) + (v102 == 5) >= 2) & 
  ((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2) & 
  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &
  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &
  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),
  "tolerance5"
)
code_df <- code_df |> condition_filter(
  ((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2) & 
  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &
  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &
  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),
  "tolerance4"
)
code_df <- code_df |> condition_filter(
  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &
  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &
  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),
  "tolerance3"
)
code_df <- code_df |> condition_filter(
  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &
  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),
  "tolerance2"
)
code_df <- code_df |> condition_filter(
  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),
  "tolerance1"
)
code_df <- code_df |> mutate(
  tolerance_group = ifelse(
    is.na(tolerance_group), "tolerance0", tolerance_group
    )
  )
```

```{r}
code_df |> count(leader, tolerance_group) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()
```

```{r}
code_df |> count(tolerance_group)
```

#### Broader Tolerance Rank Groups: `less tolerant`, `in-between` and `more tolerant`
```{r}
code_df <- code_df |> 
  mutate(tolerance_broader0 = case_when(
    tolerance_group %in% c('tolerance0', 'tolerance1') ~ 'less tolerant',
    tolerance_group %in% c('tolerance2', 'tolerance3') ~ 'in between',
    TRUE ~ 'more tolerant'
  )) |>
  mutate(tolerance_broader0 = factor(
    tolerance_broader0,levels = c('more tolerant', 'in between', 'less tolerant'), ordered = TRUE
    ))
```

```{r}
code_df |> filter(leader == 1) |> count(tolerance_broader0) |> mutate(pct = (n / sum(n)) * 100)
```

#### Attempt2

Allowing some inconsistency?
```{r}
library(rlang)
assign_tolerance <- function(df) {
  tests <- list(
    test5 = expr((v100 == 1) + (v101 == 5) + (v102 == 5) >= 2),
    test4 = expr((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2),
    test3 = expr((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2),
    test2 = expr((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2),
    test1 = expr((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2)
  )

  for (name in names(tests)) {
    df[[name]] <- eval_tidy(tests[[name]], data = df)
  }
  df <- df |>
    mutate(
      tolerance = case_when(
        test5 & (test4 + test3 + test2 + test1 >= 3) ~ "tolerance5",
        test4 & (test3 + test2 + test1 >= 2) ~ "tolerance4",
        test3 & (test2 + test1 >= 1) ~ "tolerance3",
        test2 ~ "tolerance2",
        test1 ~ "tolerance1",
        TRUE ~ "tolerance0"
      )
    ) |>
    dplyr::select(-starts_with("test"))

  return(df)
}

```

```{r}
code_df <- assign_tolerance(code_df)
code_df |> count(tolerance)
```

```{r}
code_df |> count(leader, tolerance) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()
```
```{r}
code_df <- code_df |> 
  mutate(tolerance_broader = case_when(
    tolerance %in% c('tolerance0', 'tolerance1') ~ 'less tolerant',
    tolerance %in% c('tolerance2', 'tolerance3') ~ 'in between',
    TRUE ~ 'more tolerant'
  )) |>
  mutate(tolerance_broader = factor(
    tolerance_broader,levels = c('more tolerant', 'in between', 'less tolerant'), ordered = TRUE
    ))
```
```{r}
code_df |> count(leader, tolerance_broader) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()
```

To answer this question[@stouffer1955communism, p. 51]

![](image/tolerance-distribution.png){width=50%}

##### us region

```{r}
code_df <- code_df |> mutate(us_region = case_when(
  v5 %in% c(0, 1) ~ 'east',
  v5 %in% c(2, 3) ~ 'midwest',
  v5 == 4 ~ 'south',
  TRUE ~ 'west'
)
)
```
```{r}
code_df |> filter(leader == 1) |> count(us_region, tolerance_broader) |> group_by(us_region) |> mutate(pct = n / sum(n) * 100) |> ungroup()
```

## Scale2: Scale of the Perception on the Internal Communist Danger

```{r}
code_df <- code_df |> mutate(danger = NA_character_)
```
```{r}
code_df <- code_df |> 
  mutate(
    danger5_plus = (v75 == 1),
    danger4_plus = (v66 == 1),
    danger3_plus = (v42 %in% c(1, 2)),
    danger2_plus = (v71 == 8 | v72 %in% c(1, 2, 8)),
    danger1_plus = (v68 == 8 | v69 %in% c(1, 2, 8))
  )
code_df <- code_df |> mutate(
  danger = case_when(
    danger5_plus & (danger4_plus + danger3_plus + danger2_plus + danger1_plus >= 4) ~ "danger5",
    danger4_plus & (danger3_plus + danger2_plus + danger1_plus >= 2) ~ "danger4",
    danger3_plus & (danger2_plus + danger1_plus >= 1) ~ "danger3",
    danger2_plus ~ "danger2",
    (danger5_plus + danger4_plus + danger3_plus + danger2_plus + danger1_plus == 0) ~ "danger0",
    TRUE ~ "danger1"
  )
)

```
```{r}
code_df |> count(danger, .drop = FALSE)
```

### Broader rank groups

```{r}
code_df <- code_df |> mutate(danger_broader = case_when(
  danger %in% c('danger5', 'danger4') ~ 'great threat',
  danger %in% c('danger3', 'danger2') ~ 'in between',
  TRUE ~ 'little threat'
))
```

```{r}
code_df |> count(danger_broader)
```

```{r}
cols_drop <- c("danger5_plus", "danger4_plus", "danger3_plus", "danger2_plus", "danger1_plus")
code_df <- code_df |> dplyr::select(-all_of(cols_drop))
```

### Data and Measures: Validility

From the conceptual variable Tolerance to the operationalized definition of tolerance, that maps answers of the respondent to tolerance group that correspond to their degree of tolerance. But is this tolerance scale really measuring people's tolerance or is it measuring something else.[@tesslerSocialScienceResearch2022, pp.43-47]

## Evaluating Operationallizations: Reliability and Validity, insights from classfication algorithms

```{r}
df_combined <- read_csv('data/df-combined.csv')
```

### 3-class classification using the strict measure of tolerance score `tolerance_broader0`
```{r}
# df_combined |> colnames() |> View()
```
```{r}
tolerance_df0 <- df_combined |> dplyr::select(-all_of(c("study_identification", "interview_number", "type_interview", 
"sample_number","interested", "categorizer",
"tolerance_group", "tolerance_broader", "tolerance", "danger", "danger_broader")))
```

```{r}
tolerance_df0 |> filter(leader == 1) |> count(tolerance_broader0)
```

```{r}
tolerance_df0$tolerance_broader0 <- factor(tolerance_df0$tolerance_broader0, levels = c("more tolerant","in between", "less tolerant"))
```

```{r}
tolerance_df0 <- tolerance_df0 |>
  mutate(across(-tolerance_broader0, ~ as.factor(.)))

```

```{r}
set.seed(5450)
train_indices <- sample(6433, size = 5146)

trainset <- tolerance_df0 |> slice(train_indices)
testset  <- tolerance_df0 |> slice(-train_indices)
```

```{r}
x_train <- model.matrix(tolerance_broader0~ . - 1, data = trainset)
y_train <- trainset$tolerance_broader0

x_test  <- model.matrix(tolerance_broader0~ . - 1, data = testset)
y_test  <- testset$tolerance_broader0

```

### 3-class classification

```{.r}
clf0 <- cv.glmnet(
  x_train, y_train, family = "multinomial",
  alpha = 1, type.multinomial = "ungrouped", nfolds = 5
)
```
```{.r}
lambda_1se0 <- clf0$lambda.1se
lambda_1se0

plot(clf0)
```

```{.r}
yp_train <- predict(clf0, newx = x_train, s = lambda_1se0, type = 'class')
train_acc <- mean(yp_train == y_train)
train_acc
```

```{.r}
yp_test <- predict(clf0, newx = x_test, s = lambda_1se0, type = 'class')
test_acc <- mean(yp_test == y_test)
test_acc
```
```{.r}
yp_test <- factor(yp_test, levels = c("more tolerant","in between", "less tolerant"))
y_test  <- factor(y_test, levels = c("more tolerant","in between", "less tolerant"))
lr_cm0 <- confusionMatrix(yp_test, y_test)
lr_cm0
```

```{.r}
coef_list <- coef(clf0, s = lambda_1se0)
```
```{.r}
coefs_df <- map_dfr(names(coef_list), function(class_name) {
  coefs <- coef_list[[class_name]]
  tibble(
    predictor = rownames(coefs),
    coefficient = as.numeric(coefs)
  ) |>
    filter(coefficient != 0) |> 
    arrange(desc(abs(coefficient))) |>
    mutate(
      tolerance_broader0 = class_name,
      rank = row_number()
    ) |>
    dplyr::select(tolerance_broader0, predictor, coefficient, rank)
})
# coefs_df |> write_csv("data/lr-coefs-1se0.csv")
```

```{.r}
test_result <- tibble(
  true_class0 = y_test,
  pred_class0 = yp_test
)
```

```{.r}
tolerance_df0
```

### 3-class classification: `tolerance_broader` based on the measure with wiggle room

```{.r}
tolerance_df <- df_combined |> dplyr::select(-all_of(c("study_identification", "interview_number", "type_interview", 
"sample_number","interested", "categorizer",
"tolerance_group", "tolerance_broader0", "tolerance", "danger", "danger_broader")))
```
```{.r}
tolerance_df$tolerance_broader <- factor(tolerance_df$tolerance_broader, levels = c("more tolerant","in between", "less tolerant"))
```
```{.r}
tolerance_df <- tolerance_df |>
  mutate(across(-tolerance_broader, ~ as.factor(.)))
```
```{.r}
set.seed(545)
train_indices <- sample(6433, size = 5146)

trainset <- tolerance_df |> slice(train_indices)
testset  <- tolerance_df |> slice(-train_indices)
```
```{.r}
x_train <- model.matrix(tolerance_broader~ . - 1, data = trainset)
y_train <- trainset$tolerance_broader

x_test  <- model.matrix(tolerance_broader~ . - 1, data = testset)
y_test  <- testset$tolerance_broader
```
```{.r}
clf <- cv.glmnet(
  x_train, y_train,family = "multinomial",
  alpha = 1, type.multinomial = "ungrouped", nfolds = 5
)
```
```{.r}
lambda_1se <- clf$lambda.1se
```

```{.r}
plot(clf)
```

```{.r}
yp_train <- predict(clf, newx = x_train, s = lambda_1se, type = 'class')
train_acc <- mean(yp_train == y_train)
train_acc
```

```{.r}
yp_test <- predict(clf, newx = x_test, s = lambda_1se, type = 'class')
test_acc <- mean(yp_test == y_test)
test_acc
```
```{.r}
yp_test <- factor(yp_test, levels = c("more tolerant","in between", "less tolerant"))
y_test  <- factor(y_test, levels = c("more tolerant","in between", "less tolerant"))
lr_cm <- confusionMatrix(yp_test, y_test)
lr_cm
```

```{.r}
coef_list <- coef(clf, s = lambda_1se)
```
```{.r}
coefs_df <- map_dfr(names(coef_list), function(class_name) {
  coefs <- coef_list[[class_name]]
  tibble(
    predictor = rownames(coefs),
    coefficient = as.numeric(coefs)
  ) |>
    filter(coefficient != 0) |>
    arrange(desc(abs(coefficient))) |>
    mutate(
      tolerance_broader = class_name,
      rank = row_number()
    ) |>
    dplyr::select(tolerance_broader, predictor, coefficient, rank)
})

# coefs_df |> write_csv("lr-coefs-1se.csv")
```

```{r}
# tolernace_items |> View()
```

### Are these selected Items capturing most of the variances?

```{.r}
label_lookup <- read_csv('data/gbv_labels.csv')
```

```{.r}
tolerance_item_labels <- label_lookup |> filter(v_name %in% tolernace_items) |> pull(v_label)
```

```{r}
# tolerance_item_labels |> View()
```

### Truly Learning: dropping the 15 items that contribute to the tolerance scaling

```{.r}
tolerance_df3 <- df_combined |> dplyr::select(-all_of(c("study_identification", "interview_number", "type_interview", 
"sample_number","interested", "categorizer",
"tolerance_group", "tolerance_broader", "tolerance", "danger", "danger_broader")))
tolerance_df3 <- tolerance_df3 |> dplyr::select(-all_of(tolerance_item_labels))
```

```{.r}
tolerance_df3 |> filter(leader == 1) |> count(tolerance_broader0)
```

```{.r}
tolerance_df3$tolerance_broader0 <- factor(tolerance_df3$tolerance_broader0, levels = c("more tolerant","in between", "less tolerant"))
```

```{.r}
tolerance_df3 <- tolerance_df3 |>
  mutate(across(-tolerance_broader0, ~ as.factor(.)))

```

```{.r}
set.seed(5450)
train_indices <- sample(6433, size = 5146)

trainset <- tolerance_df3 |> slice(train_indices)
testset  <- tolerance_df3 |> slice(-train_indices)
```

```{.r}
x_train <- model.matrix(tolerance_broader0~ . - 1, data = trainset)
y_train <- trainset$tolerance_broader0

x_test  <- model.matrix(tolerance_broader0~ . - 1, data = testset)
y_test  <- testset$tolerance_broader0

```
```{.r}
clf3 <- cv.glmnet(
  x_train, y_train, family = "multinomial",
  alpha = 0.7, type.multinomial = "ungrouped",nfolds = 5
)
```
```{.r}
lambda_1se3 <- clf3$lambda.1se
lambda_1se3
```

```{.r}
plot(clf3)
```

```{.r}
yp_train <- predict(clf3, newx = x_train, s = lambda_1se3, type = 'class')
train_acc <- mean(yp_train == y_train)
train_acc
```

```{.r}
yp_test <- predict(clf3, newx = x_test, s = lambda_1se3, type = 'class')
test_acc <- mean(yp_test == y_test)
test_acc
```
```{.r}
yp_test <- factor(yp_test, levels = c("more tolerant","in between", "less tolerant"))
y_test  <- factor(y_test, levels = c("more tolerant","in between", "less tolerant"))
lr_cm0 <- confusionMatrix(yp_test, y_test)
lr_cm0
```

### Acquired the class specific variables and their coefficients

```{.r}
coef_list <- coef(clf3, s = lambda_1se3)
```
```{.r}
coefs_df <- map_dfr(names(coef_list), function(class_name) {
  coefs <- coef_list[[class_name]]
  tibble(
    predictor = rownames(coefs),
    coefficient = as.numeric(coefs)
  ) |>
    filter(coefficient != 0) |> 
    arrange(desc(abs(coefficient))) |>
    mutate(
      tolerance_broader0 = class_name,
      rank = row_number()
    ) |>
    dplyr::select(tolerance_broader0, predictor, coefficient, rank)
})
# coefs_df |> write_csv("data/lr-coefs-1se3-elastic.csv")
```

```{.r}
coefs_df |> count(predictor)
```
```{r}
toler_rigid_tb <- table(df_combined$tolerance_group, df_combined$categorizer)
chi_test <- chisq.test(toler_rigid_tb)
chi_test
```

```{r}
chi_test$residuals
```
```{r}
toler_danger_tb <- table(df_combined$tolerance_group, df_combined$danger)
chi_test <- chisq.test(toler_danger_tb)
chi_test
```

```{r}
chi_test$residuals
```

```{r}
residuals_df <- as_tibble(as.table(chi_test$residuals), .name_repair = 'minimal') |>
  rename(
    tolerance = 1,
    danger = 2,
    residual = n
  )
```
```{r}
residuals_df |> ggplot(aes(x = danger, y = tolerance, fill = residual)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "orange", midpoint = 0, limit = c(min(residuals_df$residual), max(residuals_df$residual)), name = "Chisq Test Residual") +
  labs(
    title = "Chi-Squared Test",
    x = "Perception of Internal Communist",
    y = "Tolerance Group"
  ) +
  theme_minimal()

```

## Results

### Reflections


## Policy Recommendation

