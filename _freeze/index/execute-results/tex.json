{
  "hash": "871b53ceea5493fa571d69a826cb131c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Final Project: Data Ethics and Policy\"\nauthors:\n  - name: Christy Hsu\n    affiliation: Georgetown University\n    roles: writing\n    corresponding: true\ndf-print: kable\nbibliography: project.bib\ntitle-block-banner: '#E5DCC8'\nformat:\n  html:\n    df-print: kable\n    # embed-resources: true\n  pdf:\n    link-citations: true\nprefer-html: true\n---\n\n\n\n\n## Abstract\n\nThis project looked into an attempt in the fifties that set out to measure individual tolerance and use that measure to evaluate the impact the anti-Communism Cold War agenda—both abroad and at home—had on U.S. citizens. I saw the picking up of this 70-year-old survey data, and the analysis that accompanied it, as a chance to stroll through the data ethics concerns that can arise when holding the hope to learn about the world from data\n\n## Introduction\n\nThe online poll data library host by Roper Center was where I first came across the Stouffer Study of 1954 *Communism, Conformity, and Civil Liberties: A Cross-Section of the Nation Speaks Its Mind* by Samuel Andrew Stouffer[@fundfortherepublicCommunismConformityAmp2020]And, I gain access to the entire dataset on ICPSR[@stoufferCommunismConformityCivil1992]\n\n\n![](image/stouffer-cover.png){width=50%}\n\nI found Stouffer's attempt in the fifties to design public opion polls and, construct an innovative way of measuring the latent properties tolerance and fear in at the individual level very interesting. The tolerance scale and the perception of internal communist danger scale are not included in the data, thus a major part of this project involved returning these two target variables in order to complete the picture and reproduce that basis on which  Stouffer's was primary based. I learned much from this practice of reading and researching that past effort into conceptualizing and ooperationalizing tolerance and fear, and got my hands dirty to really apply those framing and method to the data. It gave me a chance to reflect on the many artistic and arbitrary decisions that the researcher made throughout this data analysis process.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.4     v readr     2.1.5\nv forcats   1.0.0     v stringr   1.5.1\nv ggplot2   3.5.1     v tibble    3.2.1\nv lubridate 1.9.3     v tidyr     1.3.1\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(glmnet)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLe chargement a nécessité le package : Matrix\n\nAttachement du package : 'Matrix'\n\nLes objets suivants sont masqués depuis 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLe chargement a nécessité le package : lattice\n\nAttachement du package : 'caret'\n\nL'objet suivant est masqué depuis 'package:purrr':\n\n    lift\n```\n\n\n:::\n:::\n\n\n\n## Harvest from Historical Data collection efforts: a more friendly format\n\nIn terms of not violate the redistribution policy of ICPSR, here won't be providing the converted files, rather STATA .do and .dct files constructed by the author (derived from the codebook)\n\n│   ├── read-ascii-files\n│   │   ├── gp-decode.do\n│   │   ├── lead-decode.do\n│   │   ├── sample1.dct\n│   │   └── sample2.dct\n\n## Returning target variables to the data\n\nThe tolerance that Stouffer argued upon.[@stouffer1955communism]\n\n#### Preparing the `code_df` data frame\n\n1. Cleaning column names and binding the two samples\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# read the coded csv files for both samples\npublic_df <- read_csv('data/converted/coded-public.csv')\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 4933 Columns: 152\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (152): v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15,...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlead_df <- read_csv('data/converted/coded-leader.csv')\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 1500 Columns: 151\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (151): v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15,...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# for the variables from 150 on distinguish those from public sample and those from leader sample since they represent different survey questions\n\npublic_df <- public_df |>\n  rename(\n    public_v150 = v150,\n    public_v151 = v151,\n    public_v152 = v152\n  )\nlead_df <- lead_df |>\n  rename(\n    lead_v150 = v150,\n    lead_v151 = v151\n  )\n\n# sample specific questions to the other sample, I filled the empty entries with 54\nlead_df <- lead_df |>\n  mutate(public_v150 = 54, public_v151 = 54, public_v152 = 54)\npublic_df <- public_df |>\n  mutate(lead_v150 = 54, lead_v151 = 54)\n```\n:::\n\n\n\n\n1. Adding Binary and Ternary Variables `leader`,`interested` and `categorizer`: these are the variables that Stouffer specified in his book as ways to divide the respondents and make comparisons.\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- bind_rows(public_df, lead_df)\ncode_df <- code_df |> mutate(leader = case_when(\n  lead_v150 == 54 ~ 0,\n  TRUE ~ 1\n))\ncode_df |> count(leader)\n```\n\n::: {.cell-output-display}\n\n| leader|    n|\n|------:|----:|\n|      0| 4933|\n|      1| 1500|\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> mutate(interested = case_when(\n    v123 == 1 ~ 'more',\n    v123 == 2 ~ 'more',\n    TRUE ~ 'less'\n)\n)\ncode_df |> count(leader, interested) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()\n```\n\n::: {.cell-output-display}\n\n| leader|interested |    n|      pct|\n|------:|:----------|----:|--------:|\n|      0|less       | 2155| 43.68538|\n|      0|more       | 2778| 56.31462|\n|      1|less       |  210| 14.00000|\n|      1|more       | 1290| 86.00000|\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> mutate(categorizer = case_when(\n  v127 %in% c(1, 2) ~ 'agree',\n  v127 == 8 ~'dont know',\n  TRUE ~ 'disagree'\n))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> count(leader, categorizer)|> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()\n```\n\n::: {.cell-output-display}\n\n| leader|categorizer |    n|       pct|\n|------:|:-----------|----:|---------:|\n|      0|agree       | 3127| 63.389418|\n|      0|disagree    | 1495| 30.306102|\n|      0|dont know   |  311|  6.304480|\n|      1|agree       |  806| 53.733333|\n|      1|disagree    |  669| 44.600000|\n|      1|dont know   |   25|  1.666667|\n\n:::\n:::\n\n\n\n\n## Scale1: Willingness to Tolerate Nonconformist\n\n#### Conceptual Tolerance and Operational Tolerance\n\nThe questionnaires used to rank respondents into six tolerance groups focused on four types of nonconformists:\n\n* A person who is against all churches and religion (atheist)\n* A person who favors government ownership (socialist)\n* An alleged communist (someone whose loyalty has been questioned by a Congressional Committee but swears under oath they have never been a communist)\n* An admitted communist\n\nrespondent were asked about their approval of 3 types of disposition against the above nonconfromist, and whether they agree or disagree the limitation or deprivation of the nonconformist's civil liberties, for example:\n\n1. Freedom speech:\n\n   * \"If \\_\\_\\_ wants to make a speech in your community, should he be allowed to speak or not?\"\n\n2. Book censor:\n\n   * \"Suppose he wrote a book that is in your public library. Somebody in your community suggests the book should be removed. Would you favor removing it, or not?\"\n\n3. Employment:\n\n   * Should a radio singer who is a nonconformist be fired or not?\n   * Should a college or university teacher be fired or not?\n   * Should a high school teacher be fired or not?\n   * Should someone working in a defense plant be fired or not?\n   * Should a store clerk be fired or not?\n\n4. Boycott:\n\n   * \"Suppose the radio program he is on advertises a brand of soap. Somebody in your community suggests you stop buying that soap. Would you stop or not?\"\n\n#### 0 to 5: Scaling Individual Tolerance\n\nI ran into many challenges replicating Stouffer’s results. Both the overall proportions across tolerance rankings, was unable to reproduce the group counts applying further breakdowns, such as by age, region, education, thus for comparison.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> mutate(tolerance_group = NA_character_)\ntolernace_items <- c(\n  'v100', 'v101', 'v102',\n  'v104', 'v32', 'v34',\n  'v103', 'v35', 'v37',\n  'v108', 'v109', 'v113',\n  'v106', 'v107', 'v110'\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# df0 <- code_df |> filter(\n#   ((v100 == 1) + (v101 == 5) + (v102 == 5) < 2) &\n#   ((v104 == 5) + (v32 == 1) + (v34 == 5) < 2) &\n#   ((v103 == 5) + (v35 == 1) + (v37 == 5) < 2) &\n#   ((v108 == 5) + (v109 == 1) + (v113 == 5) < 2) &\n#   ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) < 2)) |> dplyr::select(\n#     all_of(tolernace_items))\n# df0 |> View()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n## sanity check\ndf5 <- code_df |> filter(\n  ((v100 == 1) + (v101 == 5) + (v102 == 5) >= 2) &\n  ((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2) &\n  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &\n  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &\n  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2)) |> dplyr::select(\n    all_of(tolernace_items))\n# df5\ndf3 <- code_df |> filter(!((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2)) |> filter(\n  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &\n  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &\n  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2)) |> dplyr::select(\n    all_of(tolernace_items))\n# df3 |> View()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> mutate(tolerance_group = NA_character_)\n\ncondition_filter <- function(df, condition, group_name){\n  df <- df |> mutate(\n    tolerance_group = case_when(\n      is.na(tolerance_group) & !!rlang::enquo(condition) ~ group_name,\n      TRUE ~ tolerance_group\n    )\n  )\n  return(df)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> condition_filter(\n  ((v100 == 1) + (v101 == 5) + (v102 == 5) >= 2) & \n  ((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2) & \n  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &\n  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &\n  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),\n  \"tolerance5\"\n)\ncode_df <- code_df |> condition_filter(\n  ((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2) & \n  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &\n  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &\n  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),\n  \"tolerance4\"\n)\ncode_df <- code_df |> condition_filter(\n  ((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2) &\n  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &\n  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),\n  \"tolerance3\"\n)\ncode_df <- code_df |> condition_filter(\n  ((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2) &\n  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),\n  \"tolerance2\"\n)\ncode_df <- code_df |> condition_filter(\n  ((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2),\n  \"tolerance1\"\n)\ncode_df <- code_df |> mutate(\n  tolerance_group = ifelse(\n    is.na(tolerance_group), \"tolerance0\", tolerance_group\n    )\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> count(leader, tolerance_group) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()\n```\n\n::: {.cell-output-display}\n\n| leader|tolerance_group |    n|       pct|\n|------:|:---------------|----:|---------:|\n|      0|tolerance0      |  651| 13.196838|\n|      0|tolerance1      |  871| 17.656598|\n|      0|tolerance2      | 1263| 25.603081|\n|      0|tolerance3      |  951| 19.278330|\n|      0|tolerance4      |  395|  8.007298|\n|      0|tolerance5      |  802| 16.257855|\n|      1|tolerance0      |   79|  5.266667|\n|      1|tolerance1      |  182| 12.133333|\n|      1|tolerance2      |  180| 12.000000|\n|      1|tolerance3      |  246| 16.400000|\n|      1|tolerance4      |  205| 13.666667|\n|      1|tolerance5      |  608| 40.533333|\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> count(tolerance_group)\n```\n\n::: {.cell-output-display}\n\n|tolerance_group |    n|\n|:---------------|----:|\n|tolerance0      |  730|\n|tolerance1      | 1053|\n|tolerance2      | 1443|\n|tolerance3      | 1197|\n|tolerance4      |  600|\n|tolerance5      | 1410|\n\n:::\n:::\n\n\n\n\n#### Broader Tolerance Rank Groups: `less tolerant`, `in-between` and `more tolerant`\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> \n  mutate(tolerance_broader0 = case_when(\n    tolerance_group %in% c('tolerance0', 'tolerance1') ~ 'less tolerant',\n    tolerance_group %in% c('tolerance2', 'tolerance3') ~ 'in between',\n    TRUE ~ 'more tolerant'\n  )) |>\n  mutate(tolerance_broader0 = factor(\n    tolerance_broader0,levels = c('more tolerant', 'in between', 'less tolerant'), ordered = TRUE\n    ))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> filter(leader == 1) |> count(tolerance_broader0) |> mutate(pct = (n / sum(n)) * 100)\n```\n\n::: {.cell-output-display}\n\n|tolerance_broader0 |   n|  pct|\n|:------------------|---:|----:|\n|more tolerant      | 813| 54.2|\n|in between         | 426| 28.4|\n|less tolerant      | 261| 17.4|\n\n:::\n:::\n\n\n\n\n#### Attempt2\n\nAllowing some inconsistency?\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(rlang)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttachement du package : 'rlang'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLes objets suivants sont masqués depuis 'package:purrr':\n\n    %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl,\n    flatten_raw, invoke, splice\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nassign_tolerance <- function(df) {\n  tests <- list(\n    test5 = expr((v100 == 1) + (v101 == 5) + (v102 == 5) >= 2),\n    test4 = expr((v104 == 5) + (v32 == 1) + (v34 == 5) >= 2),\n    test3 = expr((v103 == 5) + (v35 == 1) + (v37 == 5) >= 2),\n    test2 = expr((v108 == 5) + (v109 == 1) + (v113 == 5) >= 2),\n    test1 = expr((v106 == 5) + (v107 == 5) + (v110 == 5) + (v106 == 8) + (v107 == 8) + (v110 == 8) >= 2)\n  )\n\n  for (name in names(tests)) {\n    df[[name]] <- eval_tidy(tests[[name]], data = df)\n  }\n  df <- df |>\n    mutate(\n      tolerance = case_when(\n        test5 & (test4 + test3 + test2 + test1 >= 3) ~ \"tolerance5\",\n        test4 & (test3 + test2 + test1 >= 2) ~ \"tolerance4\",\n        test3 & (test2 + test1 >= 1) ~ \"tolerance3\",\n        test2 ~ \"tolerance2\",\n        test1 ~ \"tolerance1\",\n        TRUE ~ \"tolerance0\"\n      )\n    ) |>\n    dplyr::select(-starts_with(\"test\"))\n\n  return(df)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- assign_tolerance(code_df)\ncode_df |> count(tolerance)\n```\n\n::: {.cell-output-display}\n\n|tolerance  |    n|\n|:----------|----:|\n|tolerance0 |  674|\n|tolerance1 |  530|\n|tolerance2 | 1334|\n|tolerance3 | 1229|\n|tolerance4 |  807|\n|tolerance5 | 1859|\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> count(leader, tolerance) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()\n```\n\n::: {.cell-output-display}\n\n| leader|tolerance  |    n|       pct|\n|------:|:----------|----:|---------:|\n|      0|tolerance0 |  604| 12.244070|\n|      0|tolerance1 |  491|  9.953375|\n|      0|tolerance2 | 1179| 23.900264|\n|      0|tolerance3 |  993| 20.129738|\n|      0|tolerance4 |  554| 11.230488|\n|      0|tolerance5 | 1112| 22.542064|\n|      1|tolerance0 |   70|  4.666667|\n|      1|tolerance1 |   39|  2.600000|\n|      1|tolerance2 |  155| 10.333333|\n|      1|tolerance3 |  236| 15.733333|\n|      1|tolerance4 |  253| 16.866667|\n|      1|tolerance5 |  747| 49.800000|\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> \n  mutate(tolerance_broader = case_when(\n    tolerance %in% c('tolerance0', 'tolerance1') ~ 'less tolerant',\n    tolerance %in% c('tolerance2', 'tolerance3') ~ 'in between',\n    TRUE ~ 'more tolerant'\n  )) |>\n  mutate(tolerance_broader = factor(\n    tolerance_broader,levels = c('more tolerant', 'in between', 'less tolerant'), ordered = TRUE\n    ))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> count(leader, tolerance_broader) |> group_by(leader) |> mutate(pct = n / sum(n) * 100) |> ungroup()\n```\n\n::: {.cell-output-display}\n\n| leader|tolerance_broader |    n|       pct|\n|------:|:-----------------|----:|---------:|\n|      0|more tolerant     | 1666| 33.772552|\n|      0|in between        | 2172| 44.030002|\n|      0|less tolerant     | 1095| 22.197446|\n|      1|more tolerant     | 1000| 66.666667|\n|      1|in between        |  391| 26.066667|\n|      1|less tolerant     |  109|  7.266667|\n\n:::\n:::\n\n\n\n\nTo answer this question[@stouffer1955communism, p. 51]\n\n![](image/tolerance-distribution.png){width=50%}\n\n##### us region\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> mutate(us_region = case_when(\n  v5 %in% c(0, 1) ~ 'east',\n  v5 %in% c(2, 3) ~ 'midwest',\n  v5 == 4 ~ 'south',\n  TRUE ~ 'west'\n)\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> filter(leader == 1) |> count(us_region, tolerance_broader) |> group_by(us_region) |> mutate(pct = n / sum(n) * 100) |> ungroup()\n```\n\n::: {.cell-output-display}\n\n|us_region |tolerance_broader |   n|       pct|\n|:---------|:-----------------|---:|---------:|\n|east      |more tolerant     | 276| 68.148148|\n|east      |in between        | 107| 26.419753|\n|east      |less tolerant     |  22|  5.432099|\n|midwest   |more tolerant     | 348| 69.322709|\n|midwest   |in between        | 123| 24.501992|\n|midwest   |less tolerant     |  31|  6.175299|\n|south     |more tolerant     | 225| 57.251908|\n|south     |in between        | 123| 31.297710|\n|south     |less tolerant     |  45| 11.450382|\n|west      |more tolerant     | 151| 75.500000|\n|west      |in between        |  38| 19.000000|\n|west      |less tolerant     |  11|  5.500000|\n\n:::\n:::\n\n\n\n\n## Scale2: Scale of the Perception on the Internal Communist Danger\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> mutate(danger = NA_character_)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> \n  mutate(\n    danger5_plus = (v75 == 1),\n    danger4_plus = (v66 == 1),\n    danger3_plus = (v42 %in% c(1, 2)),\n    danger2_plus = (v71 == 8 | v72 %in% c(1, 2, 8)),\n    danger1_plus = (v68 == 8 | v69 %in% c(1, 2, 8))\n  )\ncode_df <- code_df |> mutate(\n  danger = case_when(\n    danger5_plus & (danger4_plus + danger3_plus + danger2_plus + danger1_plus >= 4) ~ \"danger5\",\n    danger4_plus & (danger3_plus + danger2_plus + danger1_plus >= 2) ~ \"danger4\",\n    danger3_plus & (danger2_plus + danger1_plus >= 1) ~ \"danger3\",\n    danger2_plus ~ \"danger2\",\n    (danger5_plus + danger4_plus + danger3_plus + danger2_plus + danger1_plus == 0) ~ \"danger0\",\n    TRUE ~ \"danger1\"\n  )\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> count(danger, .drop = FALSE)\n```\n\n::: {.cell-output-display}\n\n|danger  |    n|\n|:-------|----:|\n|danger0 |  507|\n|danger1 |  682|\n|danger2 | 2116|\n|danger3 | 1170|\n|danger4 | 1093|\n|danger5 |  865|\n\n:::\n:::\n\n\n\n\n### Broader rank groups\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df <- code_df |> mutate(danger_broader = case_when(\n  danger %in% c('danger5', 'danger4') ~ 'great threat',\n  danger %in% c('danger3', 'danger2') ~ 'in between',\n  TRUE ~ 'little threat'\n))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncode_df |> count(danger_broader)\n```\n\n::: {.cell-output-display}\n\n|danger_broader |    n|\n|:--------------|----:|\n|great threat   | 1958|\n|in between     | 3286|\n|little threat  | 1189|\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncols_drop <- c(\"danger5_plus\", \"danger4_plus\", \"danger3_plus\", \"danger2_plus\", \"danger1_plus\")\ncode_df <- code_df |> dplyr::select(-all_of(cols_drop))\n```\n:::\n\n\n\n\n### Data and Measures: Validility\n\nFrom the conceptual variable Tolerance to the operationalized definition of tolerance, that maps answers of the respondent to tolerance group that correspond to their degree of tolerance. But is this tolerance scale really measuring people's tolerance or is it measuring something else.[@tesslerSocialScienceResearch2022, pp.43-47]\n\n## Evaluating Operationallizations: Reliability and Validity, insights from classfication algorithms\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndf_combined <- read_csv('data/df-combined.csv')\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 6433 Columns: 164\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr   (9): interested, categorizer, tolerance_group, tolerance_broader0, tol...\ndbl (155): study_identification, interview_number, type_interview, sample_nu...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n\n### 3-class classification using the strict measure of tolerance score `tolerance_broader0`\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# df_combined |> colnames() |> View()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntolerance_df0 <- df_combined |> dplyr::select(-all_of(c(\"study_identification\", \"interview_number\", \"type_interview\", \n\"sample_number\",\"interested\", \"categorizer\",\n\"tolerance_group\", \"tolerance_broader\", \"tolerance\", \"danger\", \"danger_broader\")))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntolerance_df0 |> filter(leader == 1) |> count(tolerance_broader0)\n```\n\n::: {.cell-output-display}\n\n|tolerance_broader0 |   n|\n|:------------------|---:|\n|in between         | 426|\n|less tolerant      | 261|\n|more tolerant      | 813|\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntolerance_df0$tolerance_broader0 <- factor(tolerance_df0$tolerance_broader0, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntolerance_df0 <- tolerance_df0 |>\n  mutate(across(-tolerance_broader0, ~ as.factor(.)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nset.seed(5450)\ntrain_indices <- sample(6433, size = 5146)\n\ntrainset <- tolerance_df0 |> slice(train_indices)\ntestset  <- tolerance_df0 |> slice(-train_indices)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nx_train <- model.matrix(tolerance_broader0~ . - 1, data = trainset)\ny_train <- trainset$tolerance_broader0\n\nx_test  <- model.matrix(tolerance_broader0~ . - 1, data = testset)\ny_test  <- testset$tolerance_broader0\n```\n:::\n\n\n\n\n### 3-class classification\n\n```{.r}\nclf0 <- cv.glmnet(\n  x_train, y_train, family = \"multinomial\",\n  alpha = 1, type.multinomial = \"ungrouped\", nfolds = 5\n)\n```\n```{.r}\nlambda_1se0 <- clf0$lambda.1se\nlambda_1se0\n\nplot(clf0)\n```\n\n```{.r}\nyp_train <- predict(clf0, newx = x_train, s = lambda_1se0, type = 'class')\ntrain_acc <- mean(yp_train == y_train)\ntrain_acc\n```\n\n```{.r}\nyp_test <- predict(clf0, newx = x_test, s = lambda_1se0, type = 'class')\ntest_acc <- mean(yp_test == y_test)\ntest_acc\n```\n```{.r}\nyp_test <- factor(yp_test, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\ny_test  <- factor(y_test, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\nlr_cm0 <- confusionMatrix(yp_test, y_test)\nlr_cm0\n```\n\n```{.r}\ncoef_list <- coef(clf0, s = lambda_1se0)\n```\n```{.r}\ncoefs_df <- map_dfr(names(coef_list), function(class_name) {\n  coefs <- coef_list[[class_name]]\n  tibble(\n    predictor = rownames(coefs),\n    coefficient = as.numeric(coefs)\n  ) |>\n    filter(coefficient != 0) |> \n    arrange(desc(abs(coefficient))) |>\n    mutate(\n      tolerance_broader0 = class_name,\n      rank = row_number()\n    ) |>\n    dplyr::select(tolerance_broader0, predictor, coefficient, rank)\n})\n# coefs_df |> write_csv(\"data/lr-coefs-1se0.csv\")\n```\n\n```{.r}\ntest_result <- tibble(\n  true_class0 = y_test,\n  pred_class0 = yp_test\n)\n```\n\n```{.r}\ntolerance_df0\n```\n\n### 3-class classification: `tolerance_broader` based on the measure with wiggle room\n\n```{.r}\ntolerance_df <- df_combined |> dplyr::select(-all_of(c(\"study_identification\", \"interview_number\", \"type_interview\", \n\"sample_number\",\"interested\", \"categorizer\",\n\"tolerance_group\", \"tolerance_broader0\", \"tolerance\", \"danger\", \"danger_broader\")))\n```\n```{.r}\ntolerance_df$tolerance_broader <- factor(tolerance_df$tolerance_broader, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\n```\n```{.r}\ntolerance_df <- tolerance_df |>\n  mutate(across(-tolerance_broader, ~ as.factor(.)))\n```\n```{.r}\nset.seed(545)\ntrain_indices <- sample(6433, size = 5146)\n\ntrainset <- tolerance_df |> slice(train_indices)\ntestset  <- tolerance_df |> slice(-train_indices)\n```\n```{.r}\nx_train <- model.matrix(tolerance_broader~ . - 1, data = trainset)\ny_train <- trainset$tolerance_broader\n\nx_test  <- model.matrix(tolerance_broader~ . - 1, data = testset)\ny_test  <- testset$tolerance_broader\n```\n```{.r}\nclf <- cv.glmnet(\n  x_train, y_train,family = \"multinomial\",\n  alpha = 1, type.multinomial = \"ungrouped\", nfolds = 5\n)\n```\n```{.r}\nlambda_1se <- clf$lambda.1se\n```\n\n```{.r}\nplot(clf)\n```\n\n```{.r}\nyp_train <- predict(clf, newx = x_train, s = lambda_1se, type = 'class')\ntrain_acc <- mean(yp_train == y_train)\ntrain_acc\n```\n\n```{.r}\nyp_test <- predict(clf, newx = x_test, s = lambda_1se, type = 'class')\ntest_acc <- mean(yp_test == y_test)\ntest_acc\n```\n```{.r}\nyp_test <- factor(yp_test, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\ny_test  <- factor(y_test, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\nlr_cm <- confusionMatrix(yp_test, y_test)\nlr_cm\n```\n\n```{.r}\ncoef_list <- coef(clf, s = lambda_1se)\n```\n```{.r}\ncoefs_df <- map_dfr(names(coef_list), function(class_name) {\n  coefs <- coef_list[[class_name]]\n  tibble(\n    predictor = rownames(coefs),\n    coefficient = as.numeric(coefs)\n  ) |>\n    filter(coefficient != 0) |>\n    arrange(desc(abs(coefficient))) |>\n    mutate(\n      tolerance_broader = class_name,\n      rank = row_number()\n    ) |>\n    dplyr::select(tolerance_broader, predictor, coefficient, rank)\n})\n\n# coefs_df |> write_csv(\"lr-coefs-1se.csv\")\n```\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# tolernace_items |> View()\n```\n:::\n\n\n\n\n### Are these selected Items capturing most of the variances?\n\n```{.r}\nlabel_lookup <- read_csv('data/gbv_labels.csv')\n```\n\n```{.r}\ntolerance_item_labels <- label_lookup |> filter(v_name %in% tolernace_items) |> pull(v_label)\n```\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# tolerance_item_labels |> View()\n```\n:::\n\n\n\n\n### Truly Learning: dropping the 15 items that contribute to the tolerance scaling\n\n```{.r}\ntolerance_df3 <- df_combined |> dplyr::select(-all_of(c(\"study_identification\", \"interview_number\", \"type_interview\", \n\"sample_number\",\"interested\", \"categorizer\",\n\"tolerance_group\", \"tolerance_broader\", \"tolerance\", \"danger\", \"danger_broader\")))\ntolerance_df3 <- tolerance_df3 |> dplyr::select(-all_of(tolerance_item_labels))\n```\n\n```{.r}\ntolerance_df3 |> filter(leader == 1) |> count(tolerance_broader0)\n```\n\n```{.r}\ntolerance_df3$tolerance_broader0 <- factor(tolerance_df3$tolerance_broader0, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\n```\n\n```{.r}\ntolerance_df3 <- tolerance_df3 |>\n  mutate(across(-tolerance_broader0, ~ as.factor(.)))\n\n```\n\n```{.r}\nset.seed(5450)\ntrain_indices <- sample(6433, size = 5146)\n\ntrainset <- tolerance_df3 |> slice(train_indices)\ntestset  <- tolerance_df3 |> slice(-train_indices)\n```\n\n```{.r}\nx_train <- model.matrix(tolerance_broader0~ . - 1, data = trainset)\ny_train <- trainset$tolerance_broader0\n\nx_test  <- model.matrix(tolerance_broader0~ . - 1, data = testset)\ny_test  <- testset$tolerance_broader0\n\n```\n```{.r}\nclf3 <- cv.glmnet(\n  x_train, y_train, family = \"multinomial\",\n  alpha = 0.7, type.multinomial = \"ungrouped\",nfolds = 5\n)\n```\n```{.r}\nlambda_1se3 <- clf3$lambda.1se\nlambda_1se3\n```\n\n```{.r}\nplot(clf3)\n```\n\n```{.r}\nyp_train <- predict(clf3, newx = x_train, s = lambda_1se3, type = 'class')\ntrain_acc <- mean(yp_train == y_train)\ntrain_acc\n```\n\n```{.r}\nyp_test <- predict(clf3, newx = x_test, s = lambda_1se3, type = 'class')\ntest_acc <- mean(yp_test == y_test)\ntest_acc\n```\n```{.r}\nyp_test <- factor(yp_test, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\ny_test  <- factor(y_test, levels = c(\"more tolerant\",\"in between\", \"less tolerant\"))\nlr_cm0 <- confusionMatrix(yp_test, y_test)\nlr_cm0\n```\n\n### Acquired the class specific variables and their coefficients\n\n```{.r}\ncoef_list <- coef(clf3, s = lambda_1se3)\n```\n```{.r}\ncoefs_df <- map_dfr(names(coef_list), function(class_name) {\n  coefs <- coef_list[[class_name]]\n  tibble(\n    predictor = rownames(coefs),\n    coefficient = as.numeric(coefs)\n  ) |>\n    filter(coefficient != 0) |> \n    arrange(desc(abs(coefficient))) |>\n    mutate(\n      tolerance_broader0 = class_name,\n      rank = row_number()\n    ) |>\n    dplyr::select(tolerance_broader0, predictor, coefficient, rank)\n})\n# coefs_df |> write_csv(\"data/lr-coefs-1se3-elastic.csv\")\n```\n\n```{.r}\ncoefs_df |> count(predictor)\n```\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntoler_rigid_tb <- table(df_combined$tolerance_group, df_combined$categorizer)\nchi_test <- chisq.test(toler_rigid_tb)\nchi_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  toler_rigid_tb\nX-squared = 491.09, df = 10, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nchi_test$residuals\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            \n                  agree   disagree  dont know\n  tolerance0  3.6776281 -5.3964437  1.1128421\n  tolerance1 -2.3955483 -1.0211719 10.7874512\n  tolerance2  4.5040579 -6.1915000  0.3030713\n  tolerance3  2.7420911 -2.5744267 -2.8481376\n  tolerance4 -0.6175252  2.2641002 -3.6331099\n  tolerance5 -7.2561266 11.9240239 -5.4354457\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntoler_danger_tb <- table(df_combined$tolerance_group, df_combined$danger)\nchi_test <- chisq.test(toler_danger_tb)\nchi_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  toler_danger_tb\nX-squared = 410.67, df = 25, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nchi_test$residuals\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            \n                  danger0      danger1      danger2      danger3      danger4\n  tolerance0 -2.970715176 -2.658964979 -2.459910036  0.974739884  2.152232514\n  tolerance1 -4.609232171 -1.006527133  4.547776892 -1.482352369  0.006717332\n  tolerance2 -3.631408736 -5.657972356  0.475321324  2.009535358  1.330107400\n  tolerance3 -0.858497500 -0.790142288 -1.598983893  2.256620306  1.165660786\n  tolerance4  0.394465523  0.926642029 -0.167803951  0.370962087 -0.093407449\n  tolerance5 10.328080755  8.630383914 -1.058231155 -3.774441827 -3.913075010\n            \n                  danger5\n  tolerance0  4.929822736\n  tolerance1 -0.973974888\n  tolerance2  3.228408105\n  tolerance3 -0.075048875\n  tolerance4 -1.188784303\n  tolerance5 -5.126832308\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nresiduals_df <- as_tibble(as.table(chi_test$residuals), .name_repair = 'minimal') |>\n  rename(\n    tolerance = 1,\n    danger = 2,\n    residual = n\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nresiduals_df |> ggplot(aes(x = danger, y = tolerance, fill = residual)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"orange\", midpoint = 0, limit = c(min(residuals_df$residual), max(residuals_df$residual)), name = \"Chisq Test Residual\") +\n  labs(\n    title = \"Chi-Squared Test\",\n    x = \"Perception of Internal Communist\",\n    y = \"Tolerance Group\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-45-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Results\n\n### Reflections\n\n\n## Policy Recommendation\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}